---
title: "STAT570 - Final Project"
subtitle: "Data Scientist Job Posting Data"
author: "Miray Çınar & Ecenaz Tunç"
format: html
editor: visual
toc: true
highlight-style: "breeze"
eval: true
echo: true
theme: "lux"
bibliography: references.bib
---

## Introduction

\-\-\--

## Data Description

\-\-\--

## Import the Data

Let's start by importing the data. Fist, import the required libraries. If you don't already have them, you can use `install.packages()` function.

```{r}

library(tidyverse)
library(readr)

Uncleaned_DS_jobs <- read_csv("Uncleaned_DS_jobs.csv")
```

Let's start by investigating our dataset a little bit, by getting a glimpse and see the structure of the data:

```{r}
library(dplyr)
glimpse(Uncleaned_DS_jobs)
```

And also take a quick summary:

```{r}
summary(Uncleaned_DS_jobs)
```

From both `glimpse()` and `summary()` outputs, we can see that, categorical variables are in character form. We will investigate them one by one later on.

But first, let's change the column names that have blank spaces so that it will be much easy to make the analyses later.

```{r}
Uncleaned_DS_jobs <- Uncleaned_DS_jobs %>% 
  rename(Job_Title = `Job Title`, 
         Salary_Estimate = `Salary Estimate`,
         Job_Description = `Job Description`,
         Company_Name = `Company Name`, 
         Type_of_Ownership =  `Type of ownership`)
```

Take a summary again to see the data:

```{r}
summary(Uncleaned_DS_jobs)
```

From our summary, we can also see some strange values are present in the data. For instance there are some rows marked as "-1" in the Headquarters, Founded.

## Investigating the Columns

Let's investigate the columns one by one:

-   Index

    Index column is not necessary for us, so we will remove it from our data set.

```{r}
Uncleaned_DS_jobs$index <- NULL
```

-   Rating

We realized that from the summary, Rating has a minimum value as -1, but the rating should be between 1 to 5.

We need to fix that problem.

To fix this, first we need to look how many data are there with Rating = -1:

```{r}
sum(Uncleaned_DS_jobs$Rating == -1)
```

We have 50 values with Rating = -1.

And after looking in a more detailed way, we realize that the foundation year of the companies have a value -1 also we need check for them

```{r}
sum(Uncleaned_DS_jobs$Founded == -1)

```

And we can look how many rows have -1 foundation year and -1 rating:

```{r}
sum(Uncleaned_DS_jobs$Founded == -1 & Uncleaned_DS_jobs$Rating == -1)
```

Foundation year and rating variable should not be -1.

So firstly for the rating variable we give change -1 to 0.

```{r}

Uncleaned_DS_jobs$Rating[Uncleaned_DS_jobs$Rating == -1] <- 0
Uncleaned_DS_jobs$Founded[Uncleaned_DS_jobs$Founded == -1] <- NA

```

Now lets check if it worked,

```{r}
summary(Uncleaned_DS_jobs$Rating)
```

As can be seen from the summary of the rating we fix the -1 problem.

-   Founded

And we can do this same process the Founded variable. We can use mean imputation method:

```{r}
founded_mean <- mean(Uncleaned_DS_jobs$Founded, na.rm = TRUE)
Uncleaned_DS_jobs$Founded[is.na(Uncleaned_DS_jobs$Founded)] <- founded_mean
```

```{r}
summary(Uncleaned_DS_jobs$Founded)
```

From the summary we also fix the problem for Founded.

-   Company Name

When we check the Company Name variable, we see that it also has the Rating next to it:

```{r}
head(Uncleaned_DS_jobs[, c("Company_Name", "Rating")])
```

We can separate them and get rid of the Rating variable inside of Company Name to clean this variable. We can do this by `str_replace()` function.

```{r}
Uncleaned_DS_jobs$Company_Name <- str_replace(Uncleaned_DS_jobs$Company_Name, "\n[0-9.]+$", "")
```

Now we have cleaned the Company Name variable:

```{r}
head(Uncleaned_DS_jobs[, c("Company_Name", "Rating")])
```

And we can see that how many of the Company Names:

```{r}
Uncleaned_DS_jobs |> 
  count(Company_Name, sort = TRUE)
```

We can see that the company with the most positions opened is "Hatch Data Inc" and "Maxar Technologies" with 12 positions opened.

-   Size

As can be seen from the summary that we have -1 for the Size. But we have unknown category for this variable.

```{r}
summary(as.factor(Uncleaned_DS_jobs$Size))
```

So we can assign "-1" to "Unknown" category for this variable:

```{r}
Uncleaned_DS_jobs$Size[Uncleaned_DS_jobs$Size == -1] <- "Unknown"
```

```{r}
summary(as.factor(Uncleaned_DS_jobs$Size))
```

-   Competitors

There are -1 values in Competitors. We don't know their competitors' name so we can attribute them to no information

```{r}

Uncleaned_DS_jobs$Competitors[Uncleaned_DS_jobs$Competitors == "-1"] <- "No information"

```

```{r}
summary(as.factor(Uncleaned_DS_jobs$Competitors), maxsum = 6)
```

-   Location

Let's see the location variable first.

```{r}
summary(as.factor(Uncleaned_DS_jobs$Location), maxsum = 6)
```

In the Location variable, we can see that they are written with the state which they are in. So we want to separate them. For this, we can use `separate_wider_delim()` function.

```{r}
# Uncleaned_DS_jobs |> separate_wider_delim( Location,delim = ",\\s+",names = c("Location", "Location_State"))
```

But, we receive an error here. From the error, we can see that some rows are too short. Let's see that columns:

```{r}
Uncleaned_DS_jobs %>% 
  filter(
    str_count(Location, ",\\s+") != 1
    ) %>% 
  select(Location)
```

```{r}

```

-   Headquarters

For the headquarters we have -1 values also,

```{r}
sum(Uncleaned_DS_jobs$Headquarters == -1)

```

```{r}
Uncleaned_DS_jobs$Headquarters[Uncleaned_DS_jobs$Headquarters == "-1"] <- "No information"

```

-   Type Of Ownership

There are -1 values in the Type of Ownership also.

We check how many -1 values are in the variable.

```{r}
sum(Uncleaned_DS_jobs$Type_of_Ownership == -1)
```

```{r}
Uncleaned_DS_jobs$Competitors[Uncleaned_DS_jobs$Type_of_Ownership == "-1"] <- "No information"
```

Let's see the summary:

```{r}
summary(as.factor(Uncleaned_DS_jobs$Type_of_Ownership))
```

-   Salary Estimation

For Salary Estimate column, let's see the unique values we have:

```{r}
levels(as.factor(Uncleaned_DS_jobs$Salary_Estimate))
```

```{r}
sum(is.na(as.factor(Uncleaned_DS_jobs$Salary_Estimate)))
```

From this output, we can see that we have common shape for the salary estimates with 0 NA values. We can separate this column into two separate columns for obtaining lower and upper limits for the salary estimates.

```{r}
# Remove spaces in the column 
Uncleaned_DS_jobs$Salary_Estimate_wo_spaces <- Uncleaned_DS_jobs$Salary_Estimate

Uncleaned_DS_jobs$Salary_Estimate_wo_spaces <- gsub(" ", "",Uncleaned_DS_jobs$Salary_Estimate)  
# Display the updated data frame 
head(Uncleaned_DS_jobs$Salary_Estimate_wo_spaces) 
```

Now we have no blank space between the words.

```{r}
## str_view(Uncleaned_DS_jobs$Salary_Estimate_wo_spaces, "[a-z0-9]+")
```

Let's get rid of the parts at the end; Glassdoor est. and Employer est.

```{r}
Uncleaned_DS_jobs$Salary_Estimate_wo_spaces <- 
  gsub("K\\(Glassdoorest.\\)",
       "",
       Uncleaned_DS_jobs$Salary_Estimate_wo_spaces) 
```

```{r}
Uncleaned_DS_jobs$Salary_Estimate_wo_spaces <- 
  gsub("K\\(Employerest.\\)",
       "",
       Uncleaned_DS_jobs$Salary_Estimate_wo_spaces)

head(Uncleaned_DS_jobs$Salary_Estimate_wo_spaces)
```

Let's see how we can select the numbers that are remaining in the rows: we can use \[0-9\]+ for this part:

```{r}
str_view(
  Uncleaned_DS_jobs$Salary_Estimate_wo_spaces, 
  "[0-9]+")
```

```{r}
Uncleaned_DS_jobs <- Uncleaned_DS_jobs |>    
  separate_wider_regex(     
    Salary_Estimate_wo_spaces,     
    patterns = c(
      "\\$",
      Low_Limit_For_Salary = "[0-9]+",       
      "K-\\$",       
      High_Limit_For_Salary = "[0-9]+"  
      )   
    ) 
```

By using `separate_wider_regex()` function, we defined the pattern in the data, and we got the new columns as Low_Limit_For_Salary and High_Limit_For_Salary as we wished.

```{r}
head(Uncleaned_DS_jobs[c("Salary_Estimate",
                         "Low_Limit_For_Salary", 
                         "High_Limit_For_Salary")])
```

For not confusing the numbers later, lets multiply the low limit and high limit numbers with 1000 and make Salary Estimate factor.

```{r}
Uncleaned_DS_jobs <- Uncleaned_DS_jobs %>%  
  mutate(
    Low_Limit_For_Salary = as.numeric(Low_Limit_For_Salary)*1000,
    High_Limit_For_Salary = as.numeric(High_Limit_For_Salary)*1000)
```

```{r}
Uncleaned_DS_jobs$Salary_Estimate <- as.factor(Uncleaned_DS_jobs$Salary_Estimate)

head(Uncleaned_DS_jobs[c("Salary_Estimate",
                         "Low_Limit_For_Salary", 
                         "High_Limit_For_Salary")])
```

-   Job Title

For Job Title column, first let's examine it:

```{r}
glimpse(
  as.factor(
    Uncleaned_DS_jobs$Job_Title))
```

As we can see, we have 172 different levels for Job Titles. We can try to group them by searching common words.

```{r}
head(
  levels(
    as.factor(
      Uncleaned_DS_jobs$Job_Title)))
```

But before that, we can see that some columns have "Senior", "Manager" words. By using this information, we can create a new column for seniority of the job.

By using `str_view()` function, first, let's see that columns;

```{r}
str_view(
  Uncleaned_DS_jobs$Job_Title, 
  regex("^Senior|^Sr|^Experience", 
        multiline = TRUE))
```

By using `str_detect()` function, we can detect the rows including "Senior", "Sr", "Experienced", "Manager" words. This function returns TRUE if they exist, and returns FALSE if they don't exist.

By using `as.integer()` , we assign 1 to exists and 0 to nonexistent.

```{r}
Uncleaned_DS_jobs$Senior_Position <- as.integer(
  str_detect(Uncleaned_DS_jobs$Job_Title, 
             regex("^(Senior|Sr|Experienced)")
             ) )
```

Now that we defined the senior roles, we can assign the same titles to same jobs.

Let's start by Data Scientist. Let's find the columns including Data Scientist word.

```{r}
str_view(Uncleaned_DS_jobs$Job_Title, 
         regex(".*Data\\s+Scientist.*", 
         multiline = TRUE))
```

Bu using `str_replace_all()` we can replace all the rows including Data Scientist word in some way, directly with "Data Scientist".

```{r}
Uncleaned_DS_jobs$Job_Title <-  
  str_replace_all(
    Uncleaned_DS_jobs$Job_Title,
    ".*Data\\s+Scientist.*",
    "Data Scientist")
```

Now let's get Data Analyst titles:

```{r}
str_view(
  Uncleaned_DS_jobs$Job_Title, 
  regex(".*Data\\s+Analyst.*", 
        multiline = TRUE,
        ignore_case = TRUE))
```

```{r}
Uncleaned_DS_jobs$Job_Title <-  
  str_replace_all(
    Uncleaned_DS_jobs$Job_Title,
    ".*Data\\s+Analyst.*",
    "Data Analyst")
```

Now let's get Data Engineer titles:

```{r}
str_view(
  Uncleaned_DS_jobs$Job_Title, 
  regex(".*Data\\s+Engineer.*", 
        multiline = TRUE,
        ignore_case = TRUE))
```

```{r}
Uncleaned_DS_jobs$Job_Title <-  
  str_replace_all(
    Uncleaned_DS_jobs$Job_Title,
    ".*Data\\s+Engineer.*",
    "Data Engineer")
```

And Machine Learning Engineers:

```{r}
str_view(
  Uncleaned_DS_jobs$Job_Title, 
  regex(".*Machine\\s+Learning.*", 
        multiline = TRUE, 
        ignore_case = TRUE))
```

```{r}
Uncleaned_DS_jobs$Job_Title <-  str_replace_all(
  Uncleaned_DS_jobs$Job_Title,
  ".*Machine\\s+Learning.*",
  "Machine Learning Engineer")
```

Let's examine Managers this time:

```{r}
str_view(
  Uncleaned_DS_jobs$Job_Title, 
  regex(".*Analytics\\s+Manager.*|.*Data\\s+Science\\sManager.*|.*Director.*|.*Vice\\sPresident.*|.*VP.*|.*Principal.*|.*Manager.*", 
        multiline = TRUE, 
        ignore_case = TRUE))
```

Let's replace them with "Data Science and Analytics Manager"

```{r}
Uncleaned_DS_jobs$Job_Title <-  
  str_replace_all(
    Uncleaned_DS_jobs$Job_Title,
    ".*Analytics\\s+Manager.*|.*Data\\s+Science\\sManager.*|.*Director.*|.*Vice\\sPresident.*|.*VP.*|.*Principal.*|.*Manager.*",
    "Data Science and Analytics Manager")
```

Now, bu using `str_view()` function, we want to see all the jobs that have "Data" in it, but not "Data Analyst", "Data Scientist,"Data Engineer" or "Data Science and Analytics Manager" because we already took care of that titles.

```{r}
str_view(
  Uncleaned_DS_jobs$Job_Title, 
  regex("^(?!.*Data\\s+Analyst.*|.*Data\\s+Scientist.*|.*Data\\s+Science\\s+and\\s+Analytics\\s+Manager.*|.*Data\\sEngineer.*).*data.*", 
        ignore_case = TRUE))
```

We will save these as "Other Data Positions"

```{r}
Uncleaned_DS_jobs$Job_Title <-  
  str_replace_all(
    Uncleaned_DS_jobs$Job_Title,
     regex("(?!Data\\s+(Analyst|Scientist|Engineer|Science\\s+and\\s+Analytics\\s+Manager)).*Data.*"),
    "Other Data Positions" )
```

Finally, we will save all the jobs that are not include "Data" word in it and not "Machine Learning Engineer" into "Others" category because there are a lot of jobs with the titles like Scientist, Researcher etc.

```{r}
Uncleaned_DS_jobs$Job_Title <-  
  str_replace_all(
    Uncleaned_DS_jobs$Job_Title, 
    regex("^(?!.*(Data|Machine\\s+Learning\\s+Engineer)).*$"), 
    "Others")
```

Finally, let's see our clean job titles:

```{r}
Uncleaned_DS_jobs$Job_Title <- as.factor(Uncleaned_DS_jobs$Job_Title)

summary(Uncleaned_DS_jobs$Job_Title)
```

-   Job Description

When we look at the job description column,

We have so many different values but we can differentiate them into other columns like we can say that a job wants the skill SQL.

First, we need to look the job description column in a detailed way.

```{r}
view(Uncleaned_DS_jobs$Job_Description)
```

We see some common requirements and common job descriptions for jobs.

For this we can separate the columns like SQL and we can say that this jobs wants an SQL bu using factor 1 or 0.

Let's start with SQL:

In this we should check if SQL is mentioned in the variable Job_Description

```{r}
sql_mentioned <- function(description) {
  # We use tolower to match the SQL in the job description
  description <- tolower(description)
  
  # Check if SQL is mentioned
  if (grepl("\\bsql\\b", description)) {
    return(1)
  } else {
    return(0)
  }
}


```

Now we need to create a column called SQL, in this column we will see if SQL is a requirement in the job description or not.

```{r}
Uncleaned_DS_jobs$sql_needed <- sapply(Uncleaned_DS_jobs$Job_Description, sql_mentioned)
```

```{r}
Uncleaned_DS_jobs$sql_needed <- as.factor(Uncleaned_DS_jobs$sql_needed)
```

Now for Python we repeat the same process.

```{r}
python_mentioned <- function(description) {
  # We use tolower to match the python in the job description
  description <- tolower(description)
  
  # Check if python is mentioned
  if (grepl("\\bpython\\b", description)) {
    return(1)
  } else {
    return(0)
  }
}
```

```{r}
Uncleaned_DS_jobs$python_needed <- sapply(Uncleaned_DS_jobs$Job_Description, python_mentioned)
```

```{r}
Uncleaned_DS_jobs$python_needed <- as.factor(Uncleaned_DS_jobs$python_needed)
```

Now for Excel:

```{r}
excel_mentioned <- function(description) {
  # We use tolower to match the excel in the job description
  description <- tolower(description)
  
  # Check if excel is mentioned
  if (grepl("\\bexcel\\b", description)) {
    return(1)
  } else {
    return(0)
  }
}
```

```{r}
Uncleaned_DS_jobs$excel_needed <- sapply(Uncleaned_DS_jobs$Job_Description, excel_mentioned)
```

```{r}
summary(Uncleaned_DS_jobs$excel_needed)
```

```{r}
Uncleaned_DS_jobs$excel_needed <- as.factor(Uncleaned_DS_jobs$excel_needed)
```

For Hadoop:

```{r}
hadoop_mentioned <- function(description) {
  # We use tolower to match the hadoop in the job description
  description <- tolower(description)
  
  # Check if hadoop is mentioned
  if (grepl("\\bhadoop\\b", description)) {
    return(1)
  } else {
    return(0)
  }
}
```

```{r}
Uncleaned_DS_jobs$hadoop_needed <- sapply(Uncleaned_DS_jobs$Job_Description, hadoop_mentioned)
```

```{r}

summary(Uncleaned_DS_jobs$hadoop_needed)

```

```{r}
Uncleaned_DS_jobs$hadoop_needed<- as.factor(Uncleaned_DS_jobs$hadoop_needed)
```

For Spark:

```{r}
spark_mentioned <- function(description) {
  # We use tolower to match the spark in the job description
  description <- tolower(description)
  
  # Check if spark is mentioned
  if (grepl("\\bspark\\b", description)) {
    return(1)
  } else {
    return(0)
  }
}
```

```{r}
Uncleaned_DS_jobs$spark_needed <- sapply(Uncleaned_DS_jobs$Job_Description, spark_mentioned)
```

```{r}
summary(Uncleaned_DS_jobs$spark_needed)
```

```{r}
Uncleaned_DS_jobs$spark_needed <- as.factor(Uncleaned_DS_jobs$spark_needed)
```

For AWS:

```{r}
aws_mentioned <- function(description) {
  # We use tolower to match the AWS in the job description
  description <- tolower(description)
  
  # Check if AWS is mentioned
  if (grepl("\\baws\\b", description)) {
    return(1)
  } else {
    return(0)
  }
}

```

```{r}
Uncleaned_DS_jobs$aws_needed <- sapply(Uncleaned_DS_jobs$Job_Description, aws_mentioned)
```

```{r}
summary(Uncleaned_DS_jobs$aws_needed)
```

```{r}
Uncleaned_DS_jobs$aws_needed <- as.factor(Uncleaned_DS_jobs$aws_needed)
```

For Tableau:

```{r}
tableau_mentioned <- function(description) {
  # We use tolower to match the Tableau in the job description
  description <- tolower(description)
  
  # Check if Tableau is mentioned
  if (grepl("\\btableau\\b", description)) {
    return(1)
  } else {
    return(0)
  }
}
```

```{r}
Uncleaned_DS_jobs$tableau_needed <- sapply(Uncleaned_DS_jobs$Job_Description, tableau_mentioned)
```

```{r}
summary(Uncleaned_DS_jobs$tableau_needed)
```

```{r}
Uncleaned_DS_jobs$tableau_needed <- as.factor(Uncleaned_DS_jobs$tableau_needed)
```

For Big Data:

```{r}
bigdata_mentioned <- function(description) {
  # We use tolower to match the Big data in the job description
  description <- tolower(description)
  
  # Check if Big data is mentioned
  if (grepl("\\bbig-data\\b", description)) {
    return(1)
  } else {
    return(0)
  }
}
```

```{r}
Uncleaned_DS_jobs$bigdata_needed <- sapply(Uncleaned_DS_jobs$Job_Description, bigdata_mentioned)
```

```{r}
summary(Uncleaned_DS_jobs$bigdata_needed)
```

```{r}

Uncleaned_DS_jobs$bigdata_needed<- as.factor(Uncleaned_DS_jobs$bigdata_needed)
```

For Numpy:

```{r}
numpy_mentioned <- function(description) {
  # We use tolower to match the Numpy in the job description
  description <- tolower(description)
  
  # Check if Numpy is mentioned
  if (grepl("\\bnumpy\\b", description)) {
    return(1)
  } else {
    return(0)
  }
}
```

```{r}
Uncleaned_DS_jobs$numpy_needed <- sapply(Uncleaned_DS_jobs$Job_Description, numpy_mentioned)
```

```{r}
summary(Uncleaned_DS_jobs$numpy_needed)
```

```{r}
Uncleaned_DS_jobs$numpy_needed <- as.factor(Uncleaned_DS_jobs$numpy_needed)
```

For Machine Learning:

```{r}
ML_mentioned <- function(description) {
  # We use tolower to match the ML in the job description
  description <- tolower(description)
  
  # Check if ML is mentioned
  if (grepl("\\bmachine learning\\b", description)) {
    return(1)
  } else {
    return(0)
  }
}
```

```{r}
Uncleaned_DS_jobs$ML_needed <- sapply(Uncleaned_DS_jobs$Job_Description, ML_mentioned)
```

```{r}
summary(Uncleaned_DS_jobs$ML_needed)
```

```{r}
Uncleaned_DS_jobs$ML_needed<- as.factor(Uncleaned_DS_jobs$ML_needed)
```

For Deep Learning:

```{r}
DL_mentioned <- function(description) {
  # We use tolower to match the DL in the job description
  description <- tolower(description)
  
  # Check if DL is mentioned
  if (grepl("\\bdeep learning\\b", description)) {
    return(1)
  } else {
    return(0)
  }
}
```

```{r}
Uncleaned_DS_jobs$DL_needed <- sapply(Uncleaned_DS_jobs$Job_Description, DL_mentioned)
```

```{r}
summary(Uncleaned_DS_jobs$DL_needed)
```

```{r}
Uncleaned_DS_jobs$DL_needed <- as.factor(Uncleaned_DS_jobs$DL_needed)
```

For Statistics:

```{r}
stat_mentioned <- function(description) {
  # We use tolower to match the statistics in the job description
  description <- tolower(description)
  
  # Check if statistics is mentioned
  if (grepl("\\bstatistics\\b", description)) {
    return(1)
  } else {
    return(0)
  }
}
```

```{r}
Uncleaned_DS_jobs$stat_needed <- sapply(Uncleaned_DS_jobs$Job_Description, stat_mentioned)
```

```{r}
summary(Uncleaned_DS_jobs$stat_needed)
```

```{r}
Uncleaned_DS_jobs$stat_needed <- as.factor(Uncleaned_DS_jobs$stat_needed)
```

Now Let's check the new columns in our dataset:

```{r}
summary(Uncleaned_DS_jobs)
```

## References

Barr, D., & DeBruine, L. (n.d.). Data Cleaning. <https://rgup.gitlab.io/research_cycle/03_tidyr.html>

Cotton, R. (2023, February 16). *Quarto cheat sheet (previously known as RMarkdown)*. DataCamp. <https://www.datacamp.com/cheat-sheet/quarto-cheat-sheet-previously-known-as-r-markdown>

*GREP: Pattern matching and replacement*. RDocumentation. (n.d.). <https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/grep>

Rahman, R. (n.d.). \[Dataset\] Data Science Job Posting on Glassdoor. Retrieved December 20, 2023,. <https://www.kaggle.com/datasets/rashikrahmanpritom/data-science-job-posting-on-glassdoor/data>

Wickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). *R for Data Science: Import, Tidy, transform, visualize, and model data*. O'Reilly Media, Inc.
