---
title: "STAT570 - Final Project"
subtitle: "Data Scientist Job Posting Data"
author: "Miray Çınar & Ecenaz Tunç"
format: html
editor: visual
toc: true
code-fold: "show"
highlight-style: "breeze"
eval: true
echo: true
theme: "lux"
bibliography: references.bib
---

## Introduction

\-\-\--

## Data Description

\-\-\--

## Import the Data

Let's start by importing the data. Fist, import the required libraries. If you don't already have them, you can use `install.packages()` function.

```{r}

library(tidyverse)
library(readr)

Uncleaned_DS_jobs <- read_csv("Uncleaned_DS_jobs.csv")
```

Let's start by investigating our dataset a little bit, by getting a glimpse and see the structure of the data:

```{r}
library(dplyr)
glimpse(Uncleaned_DS_jobs)
```

And also take a quick summary:

```{r}
summary(Uncleaned_DS_jobs)
```

From both `glimpse()` and `summary()` outputs, we can see that, categorical variables are in character form so we have to change them into factor variables.

But first, let's change the column names that have blank spaces so that it will be much easy to make the analyses later.

```{r}
Uncleaned_DS_jobs <- Uncleaned_DS_jobs %>% 
  rename(Job_Title = `Job Title`, 
         Salary_Estimate = `Salary Estimate`,
         Job_Description = `Job Description`,
         Company_Name = `Company Name`, 
         Type_of_Ownership =  `Type of ownership`)
```

Now that we have clean names for our columns, we can transform characters into factors.

```{r}
# Uncleaned_DS_jobs <- Uncleaned_DS_jobs %>% 
  #mutate(Job_Title = as.factor(Job_Title),
   #      Salary_Estimate = as.factor(Salary_Estimate),
    #     Company_Name = as.factor(Company_Name), 
     #    Location = as.factor(Location), 
      #   Headquarters = as.factor(Headquarters),
       #  Size = as.factor(Size), 
        # Type_of_Ownership = as.factor(Type_of_Ownership), 
         #Industry = as.factor(Industry),
         #Sector = as.factor(Sector), 
         #Revenue = as.factor(Revenue), 
         #Competitors = as.factor(Competitors)) 
```

Take a summary again to see the data:

```{r}
summary(Uncleaned_DS_jobs)
```

From our summary, we can see some strange values are present in the data. For instance there are some rows marked as "-1" in the Headquarters, Founded, Type_of_Ownership, Industry, Sector and Competitors columns.

Let's see if this are the same rows or not:

```{r}
Uncleaned_DS_jobs[Uncleaned_DS_jobs$Headquarters == '-1',]
```

We realized that from the summary function rating has a minimum value as -1 but this is not right, with the view function we see that are some -1 for the rating.

```{r}
view(Uncleaned_DS_jobs)

```

We need to fix that problem.

To fix this, first we need to look how many data are there with rating -1

```{r}
sum(Uncleaned_DS_jobs$Rating == -1)
```

We have 50 values with ratings -1.

And after looking in a more detailed way, we realize that the foundation year of the companies have a value -1 also we need check for them

```{r}
sum(Uncleaned_DS_jobs$Founded == -1)

```

And we can look how many rows have -1 foundation year and -1 rating

```{r}
sum(Uncleaned_DS_jobs$Founded == -1 & Uncleaned_DS_jobs$Rating == -1)
```

Foundation year and rating variable should not be -1. So firstly for the rating variable we give change -1 to 0.

```{r}

Uncleaned_DS_jobs$Rating[Uncleaned_DS_jobs$Rating == -1] <- 0
Uncleaned_DS_jobs$Founded[Uncleaned_DS_jobs$Founded == -1] <- NA

```

Now we can use mean imputation method:

Now lets check if it worked,

```{r}
summary(Uncleaned_DS_jobs$Rating)
```

As can be seen from the summary of the rating we fix the -1 problem.

And we can do this same process the founded variable

```{r}
founded_mean <- mean(Uncleaned_DS_jobs$Founded, na.rm = TRUE)
Uncleaned_DS_jobs$Founded[is.na(Uncleaned_DS_jobs$Founded)] <- founded_mean
```

```{r}
summary(Uncleaned_DS_jobs$Founded)
```

From the summary we also fix the problem for founded.

As can be seen from the summary that we have -1 for the size. But we have unknown category for this variable.

```{r}
summary(Uncleaned_DS_jobs$Size)
```

So we can assign -1 to unknown category for this variable

```{r}
Uncleaned_DS_jobs$Size[Uncleaned_DS_jobs$Size == -1] <- "Unknown"
```

```{r}
summary(Uncleaned_DS_jobs$Size)
```

There are -1 values in competitors. We don't know their competitors' name so we can attribute them to no information

```{r}
Uncleaned_DS_jobs$Competitors <- as.character(Uncleaned_DS_jobs$Competitors)


Uncleaned_DS_jobs$Competitors[Uncleaned_DS_jobs$Competitors == "-1"] <- "No information"

```

```{r}
summary(Uncleaned_DS_jobs$Competitors)
```

For the headquarters we have -1 values also,

```{r}
sum(Uncleaned_DS_jobs$Headquarters == -1)

```

```{r}
Uncleaned_DS_jobs$Headquarters<- as.character(Uncleaned_DS_jobs$Headquarters)


Uncleaned_DS_jobs$Headquarters[Uncleaned_DS_jobs$Headquarters == "-1"] <- "No information"

```

Also, there are -1 values in the type of ownership.

We check how many -1 values are in the variable.

```{r}
sum(Uncleaned_DS_jobs$Type_of_Ownership == -1)
```

```{r}
Uncleaned_DS_jobs$Type_of_Ownership <- as.character(Uncleaned_DS_jobs$Type_of_Ownership)


Uncleaned_DS_jobs$Competitors[Uncleaned_DS_jobs$Type_of_Ownership == "-1"] <- "No information"

```

## Investigating the Columns

Let's investigate the columns one by one:

-   Salary Estimation

For Salary Estimate column, let's see the unique values we have:

```{r}
levels(as.factor(Uncleaned_DS_jobs$Salary_Estimate))
```

```{r}
sum(is.na(as.factor(Uncleaned_DS_jobs$Salary_Estimate)))
```

From this output, we can see that we have common shape for the salary estimates with 0 NA values. We can separate this column into two separate columns for obtaining lower and upper limits for the salary estimates.

```{r}
# Remove spaces in the column 
Uncleaned_DS_jobs$Salary_Estimate_wo_spaces <- Uncleaned_DS_jobs$Salary_Estimate

Uncleaned_DS_jobs$Salary_Estimate_wo_spaces <- gsub(" ", "",Uncleaned_DS_jobs$Salary_Estimate)  
# Display the updated dataframe 
head(Uncleaned_DS_jobs$Salary_Estimate_wo_spaces) 
```

Now we have no blank space between the words.

```{r}
## str_view(Uncleaned_DS_jobs$Salary_Estimate_wo_spaces, "[a-z0-9]+")
```

Let's get rid of the parts at the end; Glassdoor est. and Employer est.

```{r}
Uncleaned_DS_jobs$Salary_Estimate_wo_spaces <- 
  gsub("K\\(Glassdoorest.\\)",
       "",
       Uncleaned_DS_jobs$Salary_Estimate_wo_spaces) 
```

```{r}
Uncleaned_DS_jobs$Salary_Estimate_wo_spaces <- 
  gsub("K\\(Employerest.\\)",
       "",
       Uncleaned_DS_jobs$Salary_Estimate_wo_spaces)

head(Uncleaned_DS_jobs$Salary_Estimate_wo_spaces)
```

Let's see how we can select the numbers that are remaining in the rows: we can use \[0-9\]+ for this part:

```{r}
str_view(
  Uncleaned_DS_jobs$Salary_Estimate_wo_spaces, 
  "[0-9]+")
```

```{r}
Uncleaned_DS_jobs <- Uncleaned_DS_jobs |>    
  separate_wider_regex(     
    Salary_Estimate_wo_spaces,     
    patterns = c(
      "\\$",
      Low_Limit_For_Salary = "[0-9]+",       
      "K-\\$",       
      High_Limit_For_Salary = "[0-9]+"  
      )   
    ) 
```

By using `separate_wider_regex()` function, we defined the pattern in the data, and we got the new columns as Low_Limit_For_Salary and High_Limit_For_Salary as we wished.

```{r}
head(Uncleaned_DS_jobs[c("Salary_Estimate","Low_Limit_For_Salary", "High_Limit_For_Salary")])
```

For not confusing the numbers later, lets multiply the low limit and high limit numbers with 1000 and make Salary Estimate factor.

```{r}
Uncleaned_DS_jobs <- Uncleaned_DS_jobs %>%  
  mutate(Low_Limit_For_Salary = as.numeric(Low_Limit_For_Salary)*1000,
         High_Limit_For_Salary = as.numeric(High_Limit_For_Salary)*1000)
```

```{r}
Uncleaned_DS_jobs$Salary_Estimate <- as.factor(Uncleaned_DS_jobs$Salary_Estimate)

head(Uncleaned_DS_jobs[c("Salary_Estimate","Low_Limit_For_Salary", "High_Limit_For_Salary")])
```

-   Job Title

For Job Title column, first let's examine it:

```{r}
glimpse(
  as.factor(
    Uncleaned_DS_jobs$Job_Title))
```

As we can see, we have 172 different levels for Job Titles. We can try to group them by searching common words.

```{r}
head(
  levels(
    as.factor(
      Uncleaned_DS_jobs$Job_Title)))
```

But before that, we can see that some columns have "Senior", "Manager" words. By using this information, we can create a new column for seniority of the job.

By using `str_view()` function, first, let's see that columns;

```{r}
str_view(
  Uncleaned_DS_jobs$Job_Title, 
  regex("^Senior|^Sr|^Experience", 
        multiline = TRUE))
```

By using `str_detect()` function, we can detect the rows including "Senior", "Sr", "Experienced", "Manager" words. This function returns TRUE if they exist, and returns FALSE if they don't exist.

By using `as.integer()` , we assign 1 to exists and 0 to nonexistent.

```{r}
Uncleaned_DS_jobs$SeniorPosition <- as.integer(
  str_detect(Uncleaned_DS_jobs$Job_Title, 
             regex("^(Senior|Sr|Experienced)")
             ) )
```

Now that we defined the senior roles, we can assign the same titles to same jobs.

Let's start by Data Scientist. Let's find the columns including Data Scientist word.

```{r}
str_view(Uncleaned_DS_jobs$Job_Title, 
         regex(".*Data\\s+Scientist.*", 
         multiline = TRUE))
```

Bu using `str_replace_all()` we can replace all the rows including Data Scientist word in some way, directly with "Data Scientist".

```{r}
Uncleaned_DS_jobs$Job_Title <-  
  str_replace_all(
    Uncleaned_DS_jobs$Job_Title,
    ".*Data\\s+Scientist.*",
    "Data Scientist")
```

Now let's get Data Analyst titles:

```{r}
str_view(
  Uncleaned_DS_jobs$Job_Title, 
  regex(".*Data\\s+Analyst.*", 
        multiline = TRUE,
        ignore_case = TRUE))
```

```{r}
Uncleaned_DS_jobs$Job_Title <-  
  str_replace_all(
    Uncleaned_DS_jobs$Job_Title,
    ".*Data\\s+Analyst.*",
    "Data Analyst")
```

Now let's get Data Engineer titles:

```{r}
str_view(
  Uncleaned_DS_jobs$Job_Title, 
  regex(".*Data\\s+Engineer.*", 
        multiline = TRUE,
        ignore_case = TRUE))
```

```{r}
Uncleaned_DS_jobs$Job_Title <-  
  str_replace_all(
    Uncleaned_DS_jobs$Job_Title,
    ".*Data\\s+Engineer.*",
    "Data Engineer")
```

And Machine Learning Engineers:

```{r}
str_view(
  Uncleaned_DS_jobs$Job_Title, 
  regex(".*Machine\\s+Learning.*", 
        multiline = TRUE, 
        ignore_case = TRUE))
```

```{r}
Uncleaned_DS_jobs$Job_Title <-  str_replace_all(
  Uncleaned_DS_jobs$Job_Title,
  ".*Machine\\s+Learning.*",
  "Machine Learning Engineer")
```

Let's examine Managers this time:

```{r}
str_view(
  Uncleaned_DS_jobs$Job_Title, 
  regex(".*Analytics\\s+Manager.*|.*Data\\s+Science\\sManager.*|.*Director.*|.*Vice\\sPresident.*|.*VP.*|.*Principal.*|.*Manager.*", 
        multiline = TRUE, 
        ignore_case = TRUE))
```

Let's replace them with "Data Science and Analytics Manager"

```{r}
Uncleaned_DS_jobs$Job_Title <-  
  str_replace_all(
    Uncleaned_DS_jobs$Job_Title,
    ".*Analytics\\s+Manager.*|.*Data\\s+Science\\sManager.*|.*Director.*|.*Vice\\sPresident.*|.*VP.*|.*Principal.*|.*Manager.*",
    "Data Science and Analytics Manager")
```

Now, bu using `str_view()` function, we want to see all the jobs that have "Data" in it, but not "Data Analyst", "Data Scientist,"Data Engineer" or "Data Science and Analytics Manager" because we already took care of that titles.

```{r}
str_view(
  Uncleaned_DS_jobs$Job_Title, 
  regex("^(?!.*Data\\s+Analyst.*|.*Data\\s+Scientist.*|.*Data\\s+Science\\s+and\\s+Analytics\\s+Manager.*|.*Data\\sEngineer.*).*data.*", 
        ignore_case = TRUE))
```

We will save these as "Other Data Positions"

```{r}
Uncleaned_DS_jobs$Job_Title <-  
  str_replace_all(
    Uncleaned_DS_jobs$Job_Title,
     regex("(?!Data\\s+(Analyst|Scientist|Engineer|Science\\s+and\\s+Analytics\\s+Manager)).*Data.*"),
    "Other Data Positions" )
```

Finally, we will save all the jobs that are not include "Data" word in it and not "Machine Learning Engineer" into "Others" category because there are a lot of jobs with the titles like Scientist, Researcher etc.

```{r}
Uncleaned_DS_jobs$Job_Title <-  
  str_replace_all(
    Uncleaned_DS_jobs$Job_Title, 
    regex("^(?!.*(Data|Machine\\s+Learning\\s+Engineer)).*$"), 
    "Others")
```

Finally, let's see our clean job titles:

```{r}
Uncleaned_DS_jobs$Job_Title <- as.factor(Uncleaned_DS_jobs$Job_Title)

summary(Uncleaned_DS_jobs$Job_Title)
```

-   Job Description

When we look at the job description column,

We have so many different values but we can differentiate them into other columns like we can say that a job wants the skill SQL.

First, we need to look the job description column in a detailed way.

```{r}
view(Uncleaned_DS_jobs$Job_Description)
```

We see some common requirements and common job descriptions for jobs.

For this we can separate the columns like SQL and we can say that this jobs wants an SQL bu using factor 1 or 0.

Let's start with SQL:

In this we should check if SQL is mentioned in the variable job description

```{r}
sql_mentioned <- function(description) {
  # We use tolower to match the sql in the job description
  description <- tolower(description)
  
  # Check if SQL is mentioned
  if (grepl("\\bsql\\b", description)) {
    return(1)
  } else {
    return(0)
  }
}


```

Now we need to create a column called SQL, in this column wee see if SQLis a requirement in the job description or not.

```{r}
Uncleaned_DS_jobs$sql_needed <- sapply(Uncleaned_DS_jobs$Job_Description, sql_mentioned)
```

```{r}
Uncleaned_DS_jobs$sql_needed <- as.factor(Uncleaned_DS_jobs$sql_needed)
```

Let's check the summary of the new column and the data set:

```{r}
summary(Uncleaned_DS_jobs)
summary(Uncleaned_DS_jobs$sql_needed)

```

Now for python we repeat the same process.

```{r}
python_mentioned <- function(description) {
  # We use tolower to match the python in the job description
  description <- tolower(description)
  
  # Check if python is mentioned
  if (grepl("\\bpython\\b", description)) {
    return(1)
  } else {
    return(0)
  }
}
```

```{r}
Uncleaned_DS_jobs$python_needed <- sapply(Uncleaned_DS_jobs$Job_Description, python_mentioned)
```

```{r}
Uncleaned_DS_jobs$python_needed <- as.factor(Uncleaned_DS_jobs$python_needed)
```

```{r}
summary(Uncleaned_DS_jobs)
summary(Uncleaned_DS_jobs$sql_needed)
```

Now for Excel:

```{r}
excel_mentioned <- function(description) {
  # We use tolower to match the excel in the job description
  description <- tolower(description)
  
  # Check if excel is mentioned
  if (grepl("\\bexcel\\b", description)) {
    return(1)
  } else {
    return(0)
  }
}
```

```{r}
Uncleaned_DS_jobs$excel_needed <- sapply(Uncleaned_DS_jobs$Job_Description, excel_mentioned)
```

```{r}
summary(Uncleaned_DS_jobs$excel_needed)
```

```{r}
Uncleaned_DS_jobs$excel_needed <- as.factor(Uncleaned_DS_jobs$excel_needed)
```

```{r}
summary(Uncleaned_DS_jobs)
summary(Uncleaned_DS_jobs$excel_needed)
```

For Hadoop:

```{r}
hadoop_mentioned <- function(description) {
  # We use tolower to match the hadoop in the job description
  description <- tolower(description)
  
  # Check if hadoop is mentioned
  if (grepl("\\bhadoop\\b", description)) {
    return(1)
  } else {
    return(0)
  }
}
```

```{r}
Uncleaned_DS_jobs$hadoop_needed <- sapply(Uncleaned_DS_jobs$Job_Description, hadoop_mentioned)
```

```{r}

summary(Uncleaned_DS_jobs$hadoop_needed)

```

```{r}
Uncleaned_DS_jobs$hadoop_needed<- as.factor(Uncleaned_DS_jobs$hadoop_needed)
```

```{r}
summary(Uncleaned_DS_jobs)
```

SPARK

```{r}
spark_mentioned <- function(description) {
  # We use tolower to match the spark in the job description
  description <- tolower(description)
  
  # Check if spark is mentioned
  if (grepl("\\bspark\\b", description)) {
    return(1)
  } else {
    return(0)
  }
}
```

```{r}
Uncleaned_DS_jobs$spark_needed <- sapply(Uncleaned_DS_jobs$Job_Description, spark_mentioned)
```

```{r}
summary(Uncleaned_DS_jobs$spark_needed)
```

```{r}
Uncleaned_DS_jobs$spark_needed <- as.factor(Uncleaned_DS_jobs$spark_needed)
```

```{r}
summary(Uncleaned_DS_jobs)
```

AWS

```{r}
aws_mentioned <- function(description) {
  # We use tolower to match the AWS in the job description
  description <- tolower(description)
  
  # Check if AWS is mentioned
  if (grepl("\\baws\\b", description)) {
    return(1)
  } else {
    return(0)
  }
}

```

```{r}
Uncleaned_DS_jobs$aws_needed <- sapply(Uncleaned_DS_jobs$Job_Description, aws_mentioned)
```

```{r}
summary(Uncleaned_DS_jobs$aws_needed)
```

```{r}
Uncleaned_DS_jobs$aws_needed <- as.factor(Uncleaned_DS_jobs$aws_needed)
```

```{r}
summary(Uncleaned_DS_jobs)
```

TABLEAU

```{r}
tableau_mentioned <- function(description) {
  # We use tolower to match the Tableau in the job description
  description <- tolower(description)
  
  # Check if Tableau is mentioned
  if (grepl("\\btableau\\b", description)) {
    return(1)
  } else {
    return(0)
  }
}
```

```{r}
Uncleaned_DS_jobs$tableau_needed <- sapply(Uncleaned_DS_jobs$Job_Description, tableau_mentioned)
```

```{r}
summary(Uncleaned_DS_jobs$tableau_needed)
```

```{r}
Uncleaned_DS_jobs$tableau_needed <- as.factor(Uncleaned_DS_jobs$tableau_needed)
```

```{r}
summary(Uncleaned_DS_jobs)
```

BIG_DATA

```{r}
bigdata_mentioned <- function(description) {
  # We use tolower to match the Big data in the job description
  description <- tolower(description)
  
  # Check if Big data is mentioned
  if (grepl("\\bbig-data\\b", description)) {
    return(1)
  } else {
    return(0)
  }
}
```

```{r}
Uncleaned_DS_jobs$bigdata_needed <- sapply(Uncleaned_DS_jobs$Job_Description, bigdata_mentioned)
```

```{r}
summary(Uncleaned_DS_jobs$bigdata_needed)
```

```{r}

Uncleaned_DS_jobs$bigdata_needed<- as.factor(Uncleaned_DS_jobs$bigdata_needed)
```

```{r}
summary(Uncleaned_DS_jobs)
```

NUMPY

```{r}
numpy_mentioned <- function(description) {
  # We use tolower to match the Numpy in the job description
  description <- tolower(description)
  
  # Check if Numpy is mentioned
  if (grepl("\\bnumpy\\b", description)) {
    return(1)
  } else {
    return(0)
  }
}
```

```{r}
Uncleaned_DS_jobs$numpy_needed <- sapply(Uncleaned_DS_jobs$Job_Description, numpy_mentioned)
```

```{r}
summary(Uncleaned_DS_jobs$numpy_needed)
```

```{r}
Uncleaned_DS_jobs$numpy_needed <- as.factor(Uncleaned_DS_jobs$numpy_needed)
```

MACHINE LEARNING

```{r}
ML_mentioned <- function(description) {
  # We use tolower to match the ML in the job description
  description <- tolower(description)
  
  # Check if ML is mentioned
  if (grepl("\\bmachine learning\\b", description)) {
    return(1)
  } else {
    return(0)
  }
}
```

```{r}
Uncleaned_DS_jobs$ML_needed <- sapply(Uncleaned_DS_jobs$Job_Description, ML_mentioned)
```

```{r}
summary(Uncleaned_DS_jobs$ML_needed)
```

```{r}
Uncleaned_DS_jobs$ML_needed<- as.factor(Uncleaned_DS_jobs$ML_needed)
```

```{r}
summary(Uncleaned_DS_jobs)
```

DEEP LEARNING

```{r}
DL_mentioned <- function(description) {
  # We use tolower to match the DL in the job description
  description <- tolower(description)
  
  # Check if DL is mentioned
  if (grepl("\\bdeep learning\\b", description)) {
    return(1)
  } else {
    return(0)
  }
}
```

```{r}
Uncleaned_DS_jobs$DL_needed <- sapply(Uncleaned_DS_jobs$Job_Description, DL_mentioned)
```

```{r}
summary(Uncleaned_DS_jobs$DL_needed)
```

```{r}
Uncleaned_DS_jobs$DL_needed <- as.factor(Uncleaned_DS_jobs$DL_needed)
```

```{r}
summary(Uncleaned_DS_jobs)
```

STATISTICS

```{r}
stat_mentioned <- function(description) {
  # We use tolower to match the statistics in the job description
  description <- tolower(description)
  
  # Check if statistics is mentioned
  if (grepl("\\bstatistics\\b", description)) {
    return(1)
  } else {
    return(0)
  }
}
```

```{r}
Uncleaned_DS_jobs$stat_needed <- sapply(Uncleaned_DS_jobs$Job_Description, stat_mentioned)
```

```{r}
summary(Uncleaned_DS_jobs$stat_needed)
```

```{r}
Uncleaned_DS_jobs$stat_needed <- as.factor(Uncleaned_DS_jobs$stat_needed)
```

```{r}
summary(Uncleaned_DS_jobs)
```

## References

Barr, D., & DeBruine, L. (n.d.). Data Cleaning. <https://rgup.gitlab.io/research_cycle/03_tidyr.html>

*GREP: Pattern matching and replacement*. RDocumentation. (n.d.). <https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/grep>

Rahman, R. (n.d.). \[Dataset\] Data Science Job Posting on Glassdoor. Retrieved December 20, 2023,. <https://www.kaggle.com/datasets/rashikrahmanpritom/data-science-job-posting-on-glassdoor/data>

Wickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). *R for Data Science: Import, Tidy, transform, visualize, and model data*. O'Reilly Media, Inc.
